{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reto IA: Detección de contenido sensible en tuits de Twitter\n",
    "\n",
    "El trolling es un término del argot de internet que se refiere a una persona que intencionalmente inicia discusiones o molesta a otros publicando comentarios provocadores. El único propósito del trolling es enfadar a las personas. Se ha comparado con el flaming en el contexto del ciberacoso. Además, muchos trolls consideran que lo que hacen es un “arte”. Frecuentemente se esconden detrás del anonimato. El símbolo del trolling es un dibujo en blanco y negro de una cara con una sonrisa traviesa, que simboliza la expresión que alguien hace mientras molesta a sus víctimas.\n",
    "\n",
    "Propósito del trolling:\n",
    "- Ser una fuente de entretenimiento para el troll.\n",
    "- Ser ofensivo y argumentativo.\n",
    "- Obtener placer al molestar intensamente a los demás.\n",
    "- Buscar “presas” en internet (también conocido como tú).\n",
    "- Llamar la atención.\n",
    "- Sentirse poderoso.\n",
    "- Ganar reconocimiento.\n",
    "- Hacer enojar a la víctima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "El Dataset es se conforma por un conjunto de Twits 20001. Cada twits ya posee una etiqueta que asigna una de las dos categorías.\n",
    "#### Métrica de evaluación \n",
    " - Se hará uso de las redes neurales recurrentes (RNN) para clasificar cada twit según la clase a la que corresponda.\n",
    " \n",
    "#### Estrategia de resolución\n",
    "1. Se debe realizar el siguiente pre-procesado del texto de los Twits. Este está compuesto por:\n",
    "    - Limpieza\n",
    "    - Tokenizer\n",
    "    - Pad_sequences (Acá es necesario analizar la base de datos para seleccionar un número óptimo de secuencias)\n",
    "\n",
    "\n",
    "2. Se deben evaluar diferentes arquitecturas de red para evaluar la precisión del modelo para la clasificación. Estas arquitecturas inicialmente están compuestas por las capas: Secuantial(),Embedding(), LSTM(), Dropout(), Dense(). Los parámetros a evaluar son la dimensión de la capa Embedding() para los valores [32,64,128] y las de la capa LSTM() para los valores [64,128,196]. La función de pérdida será una suma cuadrática. Al final se obtendrá un vector de probabilidades, por lo que se puede asignar la categoría en función de la probabilidad.\n",
    "    \n",
    "3. Evaluar algunas variaciones en el modelo (Opcional)\n",
    "    - Se cambiará la función de activación de la capa Dense por una Relu \n",
    "    - Se definirá una tasa de aprendizaje de 1e-5 y un decaimiento de 1e-5\n",
    "    - La capa Embedding tendrà una capa de salida 128 elementos\n",
    "    - La capa LSTM tendrá como dimensión del espacio de salida un valor de 196\n",
    "    - La función de perdida será una crosentropía binária\n",
    "    - El modelo tendrá en cuenta el desbalance que hay en la cantidad de datos que hay en las cateogrías.\n",
    "    - El número de epocas será aumentado a 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking s...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats n...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ill save you the trouble sister. Here comes a ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Im dead serious.Real athletes never cheat don...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>...go absolutely insane.hate to be the bearer ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lmao  im watching the same thing ahaha. The ga...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LOL  no he said  What do you call a jail cell ...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>truth on both counts that guy is an ass  and t...</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare nerd!</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>you are SUCH a fucking dork</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heh. Fuck 'em WHERE?!?</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>damn it i totally forgot that one!</td>\n",
       "      <td>{'notes': '', 'label': ['1']}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "0                              Get fucking real dude.   \n",
       "1    She is as dirty as they come  and that crook ...   \n",
       "2    why did you fuck it up. I could do it all day...   \n",
       "3    Dude they dont finish enclosing the fucking s...   \n",
       "4    WTF are you talking about Men? No men thats n...   \n",
       "5   Ill save you the trouble sister. Here comes a ...   \n",
       "6    Im dead serious.Real athletes never cheat don...   \n",
       "7   ...go absolutely insane.hate to be the bearer ...   \n",
       "8   Lmao  im watching the same thing ahaha. The ga...   \n",
       "9   LOL  no he said  What do you call a jail cell ...   \n",
       "10  truth on both counts that guy is an ass  and t...   \n",
       "11                                  Shakespeare nerd!   \n",
       "12                        you are SUCH a fucking dork   \n",
       "13                             Heh. Fuck 'em WHERE?!?   \n",
       "14                 damn it i totally forgot that one!   \n",
       "\n",
       "                       annotation  extras  \n",
       "0   {'notes': '', 'label': ['1']}     NaN  \n",
       "1   {'notes': '', 'label': ['1']}     NaN  \n",
       "2   {'notes': '', 'label': ['1']}     NaN  \n",
       "3   {'notes': '', 'label': ['1']}     NaN  \n",
       "4   {'notes': '', 'label': ['1']}     NaN  \n",
       "5   {'notes': '', 'label': ['1']}     NaN  \n",
       "6   {'notes': '', 'label': ['1']}     NaN  \n",
       "7   {'notes': '', 'label': ['1']}     NaN  \n",
       "8   {'notes': '', 'label': ['1']}     NaN  \n",
       "9   {'notes': '', 'label': ['1']}     NaN  \n",
       "10  {'notes': '', 'label': ['1']}     NaN  \n",
       "11  {'notes': '', 'label': ['1']}     NaN  \n",
       "12  {'notes': '', 'label': ['1']}     NaN  \n",
       "13  {'notes': '', 'label': ['1']}     NaN  \n",
       "14  {'notes': '', 'label': ['1']}     NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json('./Datos/Dataset for Detection of Cyber-Trolls.json',lines = True)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(365)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.content.apply(lambda x: len(x.split(' '))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm \n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/davidhincapie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/davidhincapie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, Dropout, GRU, SimpleRNN, Embedding\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
